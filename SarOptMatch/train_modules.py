# train_modules.py

import os
import glob  # å¦‚æœéœ€è¦é€šé…ç¬¦åŒ¹é…æ–‡ä»¶
import pickle
from datetime import datetime

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt




from . import evaluation as SarOptMatch_evaluation
from . import visualization as SarOptMatch_visualization


# === Top-5 Precision/Recall Metric ===
# (ä»£ç ä¿æŒä¸å˜)
def top5_precision_recall(y_true, y_pred_logits, top_k=5):
    y_true_flat = tf.reshape(y_true, [tf.shape(y_true)[0], -1])
    y_pred_flat = tf.reshape(y_pred_logits, [tf.shape(y_pred_logits)[0], -1])
    ground_truth_indices = tf.argmax(y_true_flat, axis=-1, output_type=tf.int32)[:, None]
    top_k_values, top_k_indices = tf.nn.top_k(y_pred_flat, k=top_k)
    correct_in_topk = tf.reduce_any(tf.equal(top_k_indices, ground_truth_indices), axis=-1)
    precision_at_topk = tf.reduce_mean(tf.cast(correct_in_topk, tf.float32))
    recall_at_topk = precision_at_topk
    return precision_at_topk, recall_at_topk


# === Best Model Saver Callback ===
class BestModelSaver(tf.keras.callbacks.Callback):
    def __init__(self, validation_data, matcher, dataset_name):
        super().__init__()
        self.validation_data = validation_data
        self.matcher = matcher  # è¿™æ˜¯ä¸€ä¸ª SarOptMatch.architectures.SAR_opt_Matcher å®ä¾‹
        self.dataset_name = dataset_name
        self.best_score = -np.inf
        self.score_history = []

    def on_epoch_end(self, epoch, logs=None):
        # å‡è®¾ matcher æœ‰ predict_heatmap æ–¹æ³•
        # å¹¶ä¸” SarOptMatch.evaluation.print_results è¿”å› euc_dists
        # æ³¨æ„ï¼šåœ¨å›è°ƒä¸­è¿›è¡Œé‡é‡çº§è¯„ä¼°ï¼ˆå¦‚ predict_heatmapï¼‰å¯èƒ½ä¼šæ˜¾è‘—å‡æ…¢è®­ç»ƒé€Ÿåº¦
        # è€ƒè™‘æ˜¯å¦å¯ä»¥ä» logs ä¸­è·å–éªŒè¯æŒ‡æ ‡ï¼Œæˆ–è€…å‡å°‘è¯„ä¼°é¢‘ç‡

        # ç¡®ä¿ self.matcher.model å­˜åœ¨
        if self.matcher.model is None:
            print("âš ï¸ [BestModelSaver] Matcher model is None, skipping score calculation.")
            if logs:  # å°è¯•ä»logsä¸­è·å–ä¸€äº›ä¿¡æ¯
                logs['score'] = -np.inf  # æˆ–è€…å…¶ä»–é»˜è®¤å€¼
            return

        # å‡è®¾ self.matcher æœ‰ predict_heatmap æ–¹æ³•
        # è¿™ä¸ªæ–¹æ³•éœ€è¦èƒ½å¤„ç† self.validation_data
        # å¹¶ä¸”è¿”å›çƒ­å›¾
        # æ³¨æ„: predict_heatmap å¯èƒ½ä¼šæ¶ˆè€—å¤§é‡æ—¶é—´å’Œèµ„æº
        print(f"\n[BestModelSaver] Epoch {epoch + 1}: Calculating score for model '{self.matcher.model_name}'...")
        try:
            # ç¡®ä¿ validation_data æ˜¯ä»¥åˆé€‚çš„æ‰¹æ¬¡å¤§å°å‡†å¤‡çš„
            # predict_heatmap å†…éƒ¨åº”è¯¥èƒ½é«˜æ•ˆå¤„ç†
            heatmaps = self.matcher.predict_heatmap(self.validation_data)  # å‡è®¾æ­¤æ–¹æ³•å­˜åœ¨

            # å‡è®¾ SarOptMatch.evaluation.print_results å­˜åœ¨å¹¶è¿”å›æ¬§æ°è·ç¦»
            # å®ƒä¹Ÿéœ€è¦ validation_data æ¥è·å–çœŸå®åç§»

            euc_dists = SarOptMatch_evaluation.print_results(self.validation_data, heatmaps)
        except Exception as e:
            print(f"âš ï¸ [BestModelSaver] Error during heatmap prediction or result printing: {e}")
            import traceback
            traceback.print_exc()
            if logs:
                logs['score'] = -np.inf  # è®°å½•ä¸€ä¸ªæ— æ•ˆåˆ†æ•°
            self.score_history.append(-np.inf)  # è®°å½•æ— æ•ˆåˆ†æ•°
            return

        acc = {
            k: round(np.mean(euc_dists <= int(k[0])), 4)
            for k in ["1px", "2px", "3px", "5px"]
        }
        avg_euc_dist = round(np.mean(euc_dists), 4)

        # è®¡ç®—åˆ†æ•°
        score = round(acc["1px"] + acc["2px"] + acc["3px"] + acc["5px"] - avg_euc_dist / 50, 4)
        self.score_history.append(score)
        print(f"[BestModelSaver] Epoch {epoch + 1}: Calculated score = {score:.4f}")

        if logs is not None:
            logs['score'] = score  # å°†åˆ†æ•°æ·»åŠ åˆ°logsä¸­ï¼Œè¿™æ ·Kerasçš„Historyå¯¹è±¡å¯èƒ½ä¼šè®°å½•å®ƒ

        if score > self.best_score:
            self.best_score = score
            # ç¡®ä¿ lambda_models ç›®å½•å­˜åœ¨
            os.makedirs("lambda_models", exist_ok=True)
            # æ„å»ºä¿å­˜è·¯å¾„
            save_path = f"lambda_models/{self.dataset_name}_best_model.h5"
            try:
                self.matcher.model.save_weights(save_path)
                print(f"ğŸ“ [BestModelSaver] New best model saved to {save_path} | score = {score:.4f}")
            except Exception as e:
                print(f"âš ï¸ [BestModelSaver] Failed to save best model weights: {e}")
        else:
            print(f"-- [BestModelSaver] No improvement | score = {score:.4f} | best = {self.best_score:.4f}")

    # (å¯é€‰) å¦‚æœæƒ³è®© score_history ä¸ Keras History ä¸€èµ·ä¿å­˜
    # def on_train_end(self, logs=None):
    #     if hasattr(self.model, 'history') and self.model.history is not None:
    #         if 'score' not in self.model.history.history : # æ£€æŸ¥æ˜¯å¦å·²è¢«logs['score']=scoreæ·»åŠ 
    #              self.model.history.history['score_from_saver'] = self.score_history
    #         print("[BestModelSaver] Score history potentially added to model's history object.")


# === Final Evaluation: Load Best Model, Predict, Visualize ===
def evaluate_best_model(matcher, validation_data, validation_dataRGB, dataset_name,extract_features=False):
    # (ä»£ç åŸºæœ¬ä¸å˜ï¼Œä½†éœ€è¦ç¡®ä¿ matcher.calculate_features æ¥å—æ­£ç¡®çš„å‚æ•°)
    print("\n-- Loading best model for final evaluation --")
    model_path = f"lambda_models/{dataset_name}_best_model.h5"
    if not os.path.exists(model_path):
        print(f"âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹: {model_path}ï¼Œæ— æ³•è¯„ä¼°")
        return

    print(f"âœ… æ‰¾åˆ°å¹¶åŠ è½½æœ€ä¼˜æ¨¡å‹: {model_path}")
    try:
        matcher.model.load_weights(model_path)
    except Exception as e:
        print(f"âŒ åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡å¤±è´¥: {e}")
        return

    print("ğŸ“Š æ­£åœ¨è¯„ä¼°æœ€ä½³æ¨¡å‹...")
    try:
        heatmaps = matcher.predict_heatmap(validation_data)  # å‡è®¾æ­¤æ–¹æ³•å­˜åœ¨
        SarOptMatch_evaluation.print_results(validation_data, heatmaps)  # æ‰“å°è¯¦ç»†ç»“æœ
    except Exception as e:
        print(f"âš ï¸ è¯„ä¼°è¿‡ç¨‹ä¸­çƒ­å›¾é¢„æµ‹æˆ–ç»“æœæ‰“å°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        # å³ä½¿è¯„ä¼°éƒ¨åˆ†å¤±è´¥ï¼Œä¹Ÿå°è¯•ç»§ç»­è¿›è¡Œç‰¹å¾æå–å’Œå¯è§†åŒ–

    # âœ… æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦æå–ç‰¹å¾å›¾
    if extract_features: # âœ… ç¡®è®¤è¿™é‡Œçš„æ¡ä»¶åˆ¤æ–­
        print("ğŸ”¥ æ­£åœ¨è®¡ç®—ç‰¹å¾å›¾...")
        feature_maps_for_vis = None
        try:
            FEATURE_EXTRACTION_BATCH_SIZE = 4
            feature_maps_for_vis = matcher.calculate_features(
                validation_data,
                batch_size_for_feature_extraction=FEATURE_EXTRACTION_BATCH_SIZE
                # output_root_dir="evaluation_features" # å¦‚æœæ‚¨çš„ calculate_features éœ€è¦è¿™ä¸ª
            )
            if feature_maps_for_vis:
                print(f"  âœ… ç‰¹å¾å›¾å·²æå– (æ•°é‡: {len(feature_maps_for_vis)}).")
            else:
                print(f"  â„¹ï¸ ç‰¹å¾å›¾æå–æœªè¿”å›ä»»ä½•å†…å®¹æˆ–è¢«è·³è¿‡ã€‚")
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾å›¾è®¡ç®—å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("â„¹ï¸ æ ¹æ®è®¾ç½®ï¼Œè·³è¿‡ç‰¹å¾å›¾æå–ã€‚") # âœ… ç¡®è®¤æœ‰è¿™ä¸ª else åˆ†æ”¯çš„æ‰“å°



# =======================================================================================
# === æ”¹åŠ¨å¼€å§‹: plot_training_curve å‡½æ•° ===
# =======================================================================================
def plot_training_curve(model_name, history_object=None, score_history_list=None):
    """
    ç»˜åˆ¶è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿ï¼Œä»¥åŠå¯é€‰çš„è¯„ä¼°åˆ†æ•°æ›²çº¿ã€‚

    Args:
        model_name (str): æ¨¡å‹çš„åç§°ï¼Œç”¨äºæ–‡ä»¶åå’Œæ ‡é¢˜ã€‚
        history_object (tf.keras.callbacks.History, optional): Kerasè®­ç»ƒå†å²å¯¹è±¡ã€‚
                                                             å¦‚æœæä¾›ï¼Œå°†ä»ä¸­æå–losså’Œval_lossã€‚
        score_history_list (list, optional): åŒ…å«æ¯è½®è¯„ä¼°åˆ†æ•°çš„åˆ—è¡¨ã€‚
                                            å¦‚æœæä¾›ï¼Œå°†ç»˜åˆ¶åœ¨ç¬¬äºŒä¸ªYè½´ä¸Šã€‚
    """
    print(f"ğŸ“Š å¼€å§‹ä¸ºæ¨¡å‹ '{model_name}' ç»˜åˆ¶è®­ç»ƒæ›²çº¿...")

    loss = []
    val_loss = []
    scores_to_plot = []  # ç”¨äºç»˜å›¾çš„åˆ†æ•°åˆ—è¡¨

    history_data_loaded = False
    if history_object and hasattr(history_object, 'history'):
        history_dict = history_object.history
        loss = history_dict.get('loss', [])
        val_loss = history_dict.get('val_loss', [])
        # å°è¯•ä» history å¯¹è±¡ä¸­è·å– 'score' (å¦‚æœ BestModelSaver å°†å…¶æ·»åŠ åˆ° logs ä¸­)
        scores_to_plot = history_dict.get('score', [])
        if scores_to_plot:
            print(f"  ä» Keras History å¯¹è±¡ä¸­è·å–åˆ° {len(scores_to_plot)} ä¸ª score å€¼ã€‚")
        history_data_loaded = True
    else:
        # å¦‚æœæ²¡æœ‰ history_objectï¼Œå°è¯•ä»æ–‡ä»¶åŠ è½½
        history_path = f"weights/{model_name}_history"  # å‡è®¾è¿™æ˜¯ Keras History å¯¹è±¡çš„ pickle æ–‡ä»¶
        if os.path.exists(history_path):
            try:
                with open(history_path, 'rb') as f:
                    loaded_history_dict = pickle.load(f)  # å‡è®¾æ–‡ä»¶å­˜çš„æ˜¯å­—å…¸æˆ–Historyå¯¹è±¡

                if isinstance(loaded_history_dict, dict):
                    loss = loaded_history_dict.get('loss', [])
                    val_loss = loaded_history_dict.get('val_loss', [])
                    scores_to_plot = loaded_history_dict.get('score', [])  # å°è¯•è·å– 'score'
                    if scores_to_plot:
                        print(f"  ä»æ–‡ä»¶ '{history_path}' çš„å­—å…¸ä¸­è·å–åˆ° {len(scores_to_plot)} ä¸ª score å€¼ã€‚")
                elif hasattr(loaded_history_dict, 'history'):  # å¦‚æœåŠ è½½çš„æ˜¯ History å¯¹è±¡
                    loss = loaded_history_dict.history.get('loss', [])
                    val_loss = loaded_history_dict.history.get('val_loss', [])
                    scores_to_plot = loaded_history_dict.history.get('score', [])
                    if scores_to_plot:
                        print(f"  ä»æ–‡ä»¶ '{history_path}' çš„ History å¯¹è±¡ä¸­è·å–åˆ° {len(scores_to_plot)} ä¸ª score å€¼ã€‚")
                else:
                    print(f"âš ï¸ æ–‡ä»¶ '{history_path}' çš„å†…å®¹æ ¼å¼æœªçŸ¥ã€‚")
                history_data_loaded = True
            except Exception as e:
                print(f"âš ï¸ ä» '{history_path}' åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°å†å²æ–‡ä»¶: {history_path} ä¸”æœªæä¾› history_objectã€‚")

    # å¦‚æœä»æ–‡ä»¶åŠ è½½çš„å†å²è®°å½•ä¸­æ²¡æœ‰ 'score'ï¼Œä½†æä¾›äº† score_history_listï¼Œåˆ™ä½¿ç”¨å®ƒ
    if not scores_to_plot and score_history_list is not None:
        scores_to_plot = score_history_list
        print(f"  ä½¿ç”¨é€šè¿‡å‚æ•°ä¼ é€’çš„ {len(scores_to_plot)} ä¸ª score å€¼ã€‚")
    elif not scores_to_plot:  # å¦‚æœåˆ°å¤„éƒ½æ‰¾ä¸åˆ°score
        print("  âš ï¸ æœªæ‰¾åˆ°æˆ–æä¾› score æ•°æ®è¿›è¡Œç»˜å›¾ã€‚")

    if not loss or not val_loss:
        if history_data_loaded:
            print("  å†å²è®°å½•ä¸­ loss æˆ– val_loss ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶æŸå¤±æ›²çº¿ã€‚")
        else:
            print("  æœªèƒ½åŠ è½½ä»»ä½•å†å²æ•°æ® (loss/val_loss)ï¼Œæ— æ³•ç»˜åˆ¶æŸå¤±æ›²çº¿ã€‚")
        # å³ä½¿æ²¡æœ‰æŸå¤±ï¼Œå¦‚æœåªæœ‰åˆ†æ•°ï¼Œä¹Ÿå¯ä»¥å°è¯•åªç»˜åˆ¶åˆ†æ•°ï¼Œä½†é€šå¸¸ä¸€èµ·ç»˜åˆ¶æ‰æœ‰æ„ä¹‰
        if not scores_to_plot:
            return  # å¦‚æœä»€ä¹ˆæ•°æ®éƒ½æ²¡æœ‰ï¼Œç›´æ¥è¿”å›

    # ç¡®ä¿æ‰€æœ‰åˆ—è¡¨é•¿åº¦ä¸€è‡´ï¼Œæˆ–è€…å–æœ€çŸ­çš„é•¿åº¦ä½œä¸ºepochèŒƒå›´
    num_epochs_loss = len(loss)
    num_epochs_val_loss = len(val_loss)
    num_epochs_score = len(scores_to_plot)

    # ä»¥lossçš„é•¿åº¦ä¸ºå‡†ï¼Œå¦‚æœå…¶ä»–åˆ—è¡¨æ›´çŸ­ï¼Œç»˜å›¾æ—¶ä¼šå‡ºé—®é¢˜
    # é€šå¸¸å®ƒä»¬åº”è¯¥ç­‰é•¿ï¼Œä»£è¡¨æ¯ä¸ªepochçš„æ•°æ®
    if num_epochs_loss == 0 and num_epochs_score > 0:  # åªæœ‰score
        epochs_range = range(1, num_epochs_score + 1)
        print("  ä»…ç»˜åˆ¶ Score æ›²çº¿ã€‚")
    elif num_epochs_loss > 0:
        epochs_range = range(1, num_epochs_loss + 1)
        if num_epochs_val_loss != num_epochs_loss and num_epochs_val_loss > 0:
            print(
                f"  è­¦å‘Š: val_loss é•¿åº¦ ({num_epochs_val_loss}) ä¸ loss é•¿åº¦ ({num_epochs_loss}) ä¸åŒ¹é…ã€‚å°†æŒ‰ loss é•¿åº¦æˆªæ–­/æ‰©å±•ã€‚")
            # ç®€å•å¤„ç†ï¼šæˆªæ–­æˆ–ç”¨NaNå¡«å……ï¼Œä½†æœ€å¥½æ˜¯ç¡®ä¿å®ƒä»¬é•¿åº¦ä¸€è‡´
        if scores_to_plot and num_epochs_score != num_epochs_loss and num_epochs_score > 0:
            print(
                f"  è­¦å‘Š: score é•¿åº¦ ({num_epochs_score}) ä¸ loss é•¿åº¦ ({num_epochs_loss}) ä¸åŒ¹é…ã€‚å°†æŒ‰ loss é•¿åº¦æˆªæ–­/æ‰©å±•ã€‚")
    else:
        print("  æ²¡æœ‰æœ‰æ•ˆçš„ epoch æ•°æ®è¿›è¡Œç»˜å›¾ã€‚")
        return

    fig, ax1 = plt.subplots(figsize=(12, 7))  # ç¨å¾®è°ƒå¤§å°ºå¯¸

    # å·¦è½´ï¼šæŸå¤±
    if loss:
        ax1.plot(epochs_range[:len(loss)], loss, label='Train Loss', color='tab:blue', marker='o', linestyle='-')
    if val_loss:
        ax1.plot(epochs_range[:len(val_loss)], val_loss, label='Val Loss', color='tab:orange', marker='^',
                 linestyle='--')

    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.tick_params(axis='y', labelcolor='tab:blue' if loss or val_loss else 'black')
    if loss or val_loss:
        ax1.legend(loc='upper left')
    ax1.grid(True, linestyle='--', alpha=0.7)

    # å³è½´ï¼šå¾—åˆ†
    if scores_to_plot:
        ax2 = ax1.twinx()  # åˆ›å»ºå…±äº«Xè½´çš„ç¬¬äºŒä¸ªYè½´
        # ç¡®ä¿ scores_to_plot çš„é•¿åº¦ä¸ epochs_range åŒ¹é…
        ax2.plot(epochs_range[:len(scores_to_plot)], scores_to_plot, label='Evaluation Score', color='tab:green',
                 marker='s', linestyle='-.')
        ax2.set_ylabel('Evaluation Score', color='tab:green')
        ax2.tick_params(axis='y', labelcolor='tab:green')
        ax2.legend(loc='upper right')

    # æ·»åŠ æ—¶é—´æˆ³å’Œæ ‡é¢˜
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    plt.title(f'{model_name} | Training Curve ({timestamp})', fontsize=14)
    fig.tight_layout()  # è°ƒæ•´å¸ƒå±€ä»¥é˜²æ­¢æ ‡ç­¾é‡å 

    # æ–‡ä»¶åä¹ŸåŠ å…¥æ—¶é—´æˆ³
    os.makedirs("weights", exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
    save_path = f"weights/{model_name}_curve_{timestamp}.png"
    try:
        plt.savefig(save_path)
        plt.close(fig)  # å…³é—­å›¾å½¢ï¼Œé‡Šæ”¾å†…å­˜
        print(f"âœ… æ›²çº¿å›¾å·²ä¿å­˜åˆ°: {save_path}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜æ›²çº¿å›¾å¤±è´¥: {e}")
        plt.close(fig)  # å³ä½¿ä¿å­˜å¤±è´¥ä¹Ÿå°è¯•å…³é—­

# =======================================================================================
# === æ”¹åŠ¨ç»“æŸ ===
# =======================================================================================
